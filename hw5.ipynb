{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea322ae",
   "metadata": {},
   "source": [
    " a.Watch this first pre-lecture video (\"Hypothesis testing. Null vs alternative\") addressing the question \"What is a hypothesis?\"\n",
    "Further Guidance\n",
    "The video gives the example that the \"Hillary versus Trump\" U.S. presidential election campaign could not be turned into a hypothesis test assessing differences in performance between the two as U.S. presidents (because at the time of the election neither had been U.S. presidents). This is different than addressing \"Obama versus Bush\" within a hypothesis testing framework (because we have eight years worth of performance of both as U.S. presidents). A more contemporarily relevant comparison then would be the aborted election campaign efforts of \"Biden versus Trump\", which would have been a chimeric hybrid of the two comparisons mentioned above (because we have BOTH four years worth of DATA regarding the performance of both as U.S. presidents BUT we are also likely still [...or, were, prior to Biden dropping out of the presidential race...] interested in asking questions regarding their potential FUTURE performance of both as U.S. presidents for which we do not yet have any data). Anway, despite Biden dropping out of the election, we might still attempt to consider the record of the Biden presidency to be informative and predictive about the furture peformance of a potential Kamala Harris presidency.\n",
    "This hopefully (a) makes the examples of the video more contemporarily relevant, and (b) gives another example to further emphasize and contrast the distinction that's being made in the video.\n",
    "Also, while these are relatively knit-picky, two technical issues that the video somewhat inaccurately introduces are:\n",
    "the video states that \"we accept the null hypothesis\"; but, actually it would be more correct to say, \"we fail to reject the null hypothesis\"\n",
    "the video specifies \"less than\" for the null hypothesis and \"less than or equal\" for the alternative hypothesis; but, actually, for mathematic reasons \"less than or equal\" version is the more technically correct choice for how the null hypothesis should be specified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf24f8b",
   "metadata": {},
   "source": [
    "It seems like you are providing a reference to a pre-lecture video about hypothesis testing and clarifying some important points discussed in the video. To summarize:\n",
    "\n",
    "1. **Hypothesis Testing**: The distinction between null and alternative hypotheses is critical. The null hypothesis (H₀) usually represents the status quo or no effect, while the alternative hypothesis (H₁) represents a significant difference or effect.\n",
    "   \n",
    "2. **Clarification of Terms**:\n",
    "   - The video uses an example of the U.S. election campaign and explains why you can't assess future performance between candidates who haven't been in office before (e.g., Hillary vs. Trump in 2016). But you could compare two individuals who have already served as presidents, such as Obama vs. Bush.\n",
    "   - The example with Biden vs. Trump is more nuanced because both have served as U.S. presidents, and while we have data about their past performance, there's still interest in their potential future performance.\n",
    "   - You then extend this to reflect how Biden’s presidency could provide insights into Kamala Harris's potential future performance.\n",
    "\n",
    "3. **Technical Adjustments**:\n",
    "   - Instead of \"accepting the null hypothesis,\" the more precise term is \"failing to reject the null hypothesis.\" This reflects the principle that we can’t definitively prove the null hypothesis; we can only determine if there is insufficient evidence to reject it.\n",
    "   - When framing the null hypothesis, it's typically defined with \"less than or equal\" (≤) rather than just \"less than.\" This is important for ensuring the hypothesis test is mathematically valid.\n",
    "\n",
    "These distinctions are essential for a rigorous understanding of hypothesis testing, especially in scientific research and data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa9a60",
   "metadata": {},
   "source": [
    "b.Watch this second pre-lecture video (\"What is a p-value\") providing an intuitivie introduction to p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ecfaa",
   "metadata": {},
   "source": [
    "A p-value is a key concept in hypothesis testing and statistics. It represents the probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis is true. Here's a simple breakdown of how p-values work:\n",
    "\n",
    "1. **Null Hypothesis (H₀)**: This is the assumption that there is no effect or no difference, and the observed data is due to random chance.\n",
    "\n",
    "2. **Alternative Hypothesis (H₁)**: This suggests that there is an effect or a difference, and the observed data is not due to random chance.\n",
    "\n",
    "3. **P-value Definition**: The p-value is the probability of observing data as extreme as what we have, or even more extreme, if the null hypothesis is true. \n",
    "\n",
    "4. **Interpreting the P-value**:\n",
    "   - **Low P-value (typically ≤ 0.05)**: This suggests that the observed data is unlikely under the null hypothesis, so we may reject the null hypothesis in favor of the alternative hypothesis.\n",
    "   - **High P-value (> 0.05)**: This means the data is consistent with the null hypothesis, and we do not have enough evidence to reject it.\n",
    "\n",
    "5. **Common Misinterpretation**: A common mistake is to think the p-value represents the probability that the null hypothesis is true. In reality, the p-value tells us how likely the observed data would occur if the null hypothesis were true—not the truth of the hypothesis itself.\n",
    "\n",
    "P-values help us decide whether the results of an experiment or study are statistically significant, but they don’t give a definitive \"yes\" or \"no\" answer regarding hypotheses. They provide a way to measure the strength of the evidence against the null hypothesis.\n",
    "\n",
    "Does this help you get a clearer idea of what the video covers, or would you like more specific details?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019a650",
   "metadata": {},
   "source": [
    "1. The \"first pre-lecture video\" (above) describes hypothesis testing as addressing \"an idea that can be tested\", and the end of the video then discusses what our actual intended purpose in setting up a null hypothesis is. What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically? What would you describe is the key \"criteria\" defining what a good null hypothesis is? And what is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? Answer these questions with concise explanations in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95305872",
   "metadata": {},
   "source": [
    "1. **Key factor between ideas that can and cannot be tested statistically**: The key factor is whether the idea is *testable and measurable with data*. For an idea to be tested statistically, it must involve variables that can be quantified and analyzed to determine patterns or relationships.\n",
    "\n",
    "2. **Criteria defining a good null hypothesis**: A good null hypothesis should be *clear, testable, and falsifiable*. It should assert that no significant effect or difference exists, and it must be formulated in a way that allows statistical testing to determine whether there is sufficient evidence to reject it.\n",
    "\n",
    "3. **Difference between null and alternative hypothesis**: \n",
    "   - The **null hypothesis (H₀)** states that there is *no effect or difference* in the data being tested, and any observed results are due to chance.\n",
    "   - The **alternative hypothesis (H₁)** suggests that there *is an effect or difference*, meaning that the observed results are not solely due to chance but indicate a real phenomenon or relationship.\n",
    "\n",
    "In essence, hypothesis testing evaluates whether there is enough evidence to reject the null hypothesis and support the alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29085290",
   "metadata": {},
   "source": [
    "2.Towards the end of the \"first pre-lecture\" video (above) it is stated that, \"It is important to note that outcomes of tests refer to the population parameter, rather than the sample statistic! As such, the result that we get is for the population.\" In terms of the distinctions between the concepts of  𝑥𝑖 's,  𝑥¯ ,  𝜇 , and  𝜇0 , how would you describe what the sentence above means? Explain this concisely in your own words for a \"non-statsitical\" audience, defining the technical statistical terminology you use in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004531e",
   "metadata": {},
   "source": [
    "In simple terms, the sentence means that when we perform statistical tests, we are trying to make conclusions about the *entire population* rather than just the specific data we collected from a sample.\n",
    "\n",
    "To explain the technical terms:\n",
    "\n",
    "1. **𝑥𝑖 (x₁, x₂, etc.)**: These are the *individual data points* in our sample. For example, if we survey 5 people about their height, 𝑥₁ might be the height of the first person, 𝑥₂ the second, and so on.\n",
    "\n",
    "2. **𝑥¯ (x-bar)**: This is the *average* of all the individual data points (𝑥𝑖's) in the sample. It's a summary of our sample data, but it doesn't represent the whole population—just the group we measured.\n",
    "\n",
    "3. **𝜇 (mu)**: This is the *true average* of the entire population, which is often unknown. Our sample (𝑥¯) is used to estimate it, but we're really interested in 𝜇.\n",
    "\n",
    "4. **𝜇₀ (mu₀)**: This is the *hypothesized average* we are testing in our null hypothesis. It’s a specific value that we assume is the true population average before collecting any data, and our test will decide if this assumption holds.\n",
    "\n",
    "So, the sentence is saying that even though we only have data from a sample (represented by 𝑥𝑖 and 𝑥¯), our conclusions are aimed at understanding the true population average (𝜇), which is what we really care about. The goal is to make an inference about the population, not just the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9169471d",
   "metadata": {},
   "source": [
    "3.The second \"Pre-lecture\" video (above) explains that we \"imagine a world where the null hypothesis is true\" when calculating a p-value? Explain why this is in your own words in a way that makes the most sense to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116355a7",
   "metadata": {},
   "source": [
    "When we calculate a p-value, we \"imagine a world where the null hypothesis is true\" because we are testing how likely our observed data would be if there really was *no effect or no difference*—just like the null hypothesis suggests.\n",
    "\n",
    "In other words, we assume that the null hypothesis is correct and that any differences we see in the data are due to random chance. By imagining this world, we can calculate the p-value, which tells us how surprising or unusual our observed data is under that assumption. If the p-value is very low, it means that what we observed is unlikely to happen by chance if the null hypothesis were true, so we might reject the null hypothesis.\n",
    "\n",
    "This approach helps us make decisions: if the data is very unlikely in a world where the null is true, we conclude that the null hypothesis probably isn't a good explanation for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f32e61",
   "metadata": {},
   "source": [
    "4.The second \"Pre-lecture\" video (above) suggests that a smaller p-value makes the null hypothesis look more ridiculous. Explain why this is in your own words in a way that makes the most sense to you, clarifying the meaning of any technical statistical terminology you use in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f045aae",
   "metadata": {},
   "source": [
    "In simple terms, a smaller p-value means that the data we observed is very unlikely to happen if the null hypothesis is true. This makes the null hypothesis look \"more ridiculous\" because it suggests that the assumption of no effect or no difference (the null hypothesis) doesn't fit well with the actual data we collected.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "- **P-value**: This is a number between 0 and 1 that tells us the probability of getting data at least as extreme as what we observed, assuming that the null hypothesis is true. A smaller p-value means this probability is very low.\n",
    "\n",
    "- **Null hypothesis**: This is the starting assumption that there is *no effect* or *no difference*. For example, if we're testing whether a new drug works better than a placebo, the null hypothesis says that the drug has no effect—that it's no better than the placebo.\n",
    "\n",
    "When we get a small p-value, it means that the chance of seeing our observed results, if the null hypothesis were true, is very slim. This makes us question the null hypothesis because if it were really true, we'd expect to see results much closer to no effect. The smaller the p-value, the more our data contradicts the null hypothesis, making it seem less believable, or \"ridiculous.\"\n",
    "\n",
    "So, a small p-value gives us stronger evidence to reject the null hypothesis and believe that there might actually be a real effect or difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c21a39",
   "metadata": {},
   "source": [
    "5.Güntürkün (2003) recorded how kissing couples tilt their heads. 80 out of 124 couples, or 64.5% tilted their heads to the right. Simulate a p-value using a \"50/50 coin-flipping\" model for the assumption of the null hypothesis  𝐻0  that the population of humans don't have left or right head tilt tendencies when kissing, and use the table below to determine the level of evidence we have against  𝐻0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31db97c",
   "metadata": {},
   "source": [
    "6.The simulated p-value for the null hypothesis (that there is no preference for head tilt when kissing) is approximately **0.0009**. This means that if there truly were no preference, there is only a 0.09% chance of observing 80 or more couples tilting their heads to the right out of 124.\n",
    "\n",
    "Using a typical significance threshold:\n",
    "- **Strong evidence** against the null hypothesis is usually when p-values are less than 0.05.\n",
    "- With a p-value of 0.0009, we have **very strong evidence** against the null hypothesis, suggesting that couples are indeed more likely to tilt their heads to the right when kissing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a87c6b",
   "metadata": {},
   "source": [
    "No, a smaller p-value cannot definitively prove that the null hypothesis is false. A p-value only tells us how likely our observed data is under the assumption that the null hypothesis is true, but it does not offer absolute proof.\n",
    "\n",
    "In the case of Fido from the \"second pre-lecture video,\" it's not possible to definitively prove that he is either innocent or guilty using a p-value. A low p-value suggests that the evidence against Fido (or against the null hypothesis) is strong, but it does not provide certainty—it just indicates that the data is unlikely to have occurred by chance if the null hypothesis were true.\n",
    "\n",
    "Similarly, a high p-value doesn't prove that Fido is innocent (or that the null hypothesis is true). It just means there isn't enough evidence to reject the null hypothesis.\n",
    "\n",
    "In summary, no p-value—no matter how low or high—can *definitely* prove or disprove anything. It only indicates the strength of the evidence for or against the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26444bd0",
   "metadata": {},
   "source": [
    "7.In the second half of the \"first pre-lecture video\" the concept of a \"one sided\" (or \"one tailed\") test is introduced in contrast to a \"two sided\" (or \"two tailed\") test. Work with a ChatBot to adjust the code from \"Demo II of the Week 5 TUT\" (which revisits the \"Vaccine Data Analysis Assignment\" from Week 04 HW \"Question 8\") in order to compute a p-value for a \"one sided\" (or \"one tailed\") hypothesis test rather than the \"two sided\" (or \"two tailed\") version it provides. Describe (perhaps with the help of your ChatBot) what changed in the code; how this changes the interpretation of the hypothesis test; and whether or not we should indeed expect the p-value to be smaller in the \"one tailed\" versus \"two tailed\" analysis.\n",
    "¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1bf840",
   "metadata": {},
   "source": [
    "To adjust the code from a two-sided (two-tailed) test to a one-sided (one-tailed) test, we need to focus on how the p-value is calculated. Here’s how the process works and what changes you would make:\n",
    "\n",
    "What changes in the code:\n",
    "Two-tailed test: In a two-tailed test, the p-value is calculated by considering the probability of obtaining a value as extreme as the observed value in either direction (both lower and higher). This involves calculating the area under both tails of the distribution.\n",
    "In the code, this would be reflected in the logic that calculates the p-value. For example, if you were using a normal distribution, the two-tailed test would look at how far the observed value is from the mean in both directions.\n",
    "One-tailed test: In a one-tailed test, the p-value is calculated only by considering one direction, depending on whether you're testing for a difference in one specific direction (greater or less). This halves the area of the distribution you're considering.\n",
    "The code would need to be adjusted to compute the p-value based on only one tail (either the left or right side). For example, if you're testing if the vaccine is better than the control, you’d only look at the upper tail (right side).\n",
    "Code Adjustment Example:\n",
    "Let’s say the two-tailed p-value is calculated using the cumulative distribution function (CDF) of a normal distribution. For a one-tailed test, you would modify it as follows:\n",
    "\n",
    "Two-tailed test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 2 * (1 - norm.cdf(abs(test_statistic)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 1 - norm.cdf(test_statistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb104f",
   "metadata": {},
   "source": [
    "Here, norm.cdf is the cumulative distribution function of the normal distribution, and test_statistic is the calculated z-score or t-score.\n",
    "How this changes the interpretation of the hypothesis test:\n",
    "Two-tailed test: We are testing for deviations in both directions (whether the vaccine is better or worse than the control). This is more conservative because it looks for any significant difference.\n",
    "One-tailed test: We are only testing for a deviation in one direction (for example, if the vaccine is better). This can be appropriate if you only care about one outcome (better performance) and are not interested in the possibility of it being worse.\n",
    "Should the p-value be smaller in a one-tailed analysis?\n",
    "Yes, the p-value in a one-tailed test will usually be smaller than in a two-tailed test because you're only considering one side of the distribution. This means you’re focusing on the specific outcome you care about (e.g., a positive effect), and the threshold for rejecting the null hypothesis is easier to meet. However, it's crucial to only use a one-tailed test if it makes sense based on your hypothesis (e.g., you have a directional expectation like \"better than control\").\n",
    "\n",
    "Let me know if you'd like me to simulate the one-tailed p-value for your example using Python!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7266f",
   "metadata": {},
   "source": [
    "8. Complete the following assignment.\n",
    "Fisher's Tea Experiment\n",
    "Overview\n",
    "A most beloved piece of statistical lore about the (most famous) statistician Ronald Fisher involves cups of tea with milk. Fisher and his friend and colleague, Dr. Muriel Bristol, worked at Cambridge in the 1920s and regularly had tea together. During one of their afternoon tea times, Bristol refused a cup of tea from Fisher because he put milk in first BEFORE pouring in the tea. Bristol said she could taste the difference, and much preferred the taste of tea when the milk was poured in afterward the tea. Fisher didn't think that there could be a difference and proposed a hypothesis test to examine the situation.\n",
    "Fisher made 8 cups of tea, 4 with milk added in first and 4 with tea added in first, and gave them to Dr. Bristol without her seeing how they were made and she would say if she thought the tea or the milk was poured first. As it turned out, Bristol correctly identified if the tea or milk was poured first for all 8 of the cups. Fisher, being a skeptical statistician wanted to test if this could be happening by chance with Bristol just randomly guessing (or whether there was evidence against an assumption of Bristol just randomly guessing), and subsequently designed a statistical hypothesis test to do so.\n",
    "Suppose you run an experiment like this with students in STA130. You get a random sample of 80 STA130 students to each taste one cup of tea and tell you whether they think the milk or tea was poured first. Suppose 49 students are able to correctly state which was poured first. Provide a statistical analysis of this experiment as guided through the following set of questions.\n",
    "Data\n",
    "49 out of a sample of 80 students are able to correctly state which was poured first.\n",
    "Deliverables\n",
    "While you can choose how to approach the project, we are interested in evaluating your report relative to the following deliverables:\n",
    "Clarity of your documentation, code, and written report\n",
    "Description of the population (and sample) and parameter of interest (and corresponding observed test statistic)\n",
    "Formal null hypotheses 𝐻0\n",
    "Provide a formal version 𝐻0 based on the population parameter\n",
    "Provide an informal interpretive statement explaining 𝐻0 in more casual everyday common language\n",
    "Alternative hypothesis 𝐻𝐴 in terms of 𝐻0\n",
    "Quantitative analysis addressing the validity of 𝐻0\n",
    "Explanation of the method clearly articulating the purpose of the usage of statistic(s) to address 𝐻0 the population parameter of interest\n",
    "Comments\n",
    "Regarding the population (and the sample), there is a clear difference between the experiment with STA130 students considered here and the original motivating experimental context of Fisher and Bristol.\n",
    "the sample size is different.\n",
    "but so too is the nature of the population. the parameter in question might be considered more personalized in the original experiment; whereas, the parameter in the context of STA130 students might be a more abstract concept\n",
    "The analysis here could be approached from the perspective of formal hypothesis testing.\n",
    "which would likely involve the simulation of a sampling distribution under 𝐻0 in order to estimate p-value with respect to the null hypothesis based on the observed test statistic (how?), concluding with the assement of 𝐻0 based on an interpretation of the meaning of the p-value relative to 𝐻0\n",
    "but a confidence interval approach to considering the hypothesis could also be considered.\n",
    "Consider organizing your report within the following outline template.\n",
    "Problem Introduction\n",
    "Relationship between this experiment and the original with Fisher and Bristol\n",
    "Statements of the Null Hypothesis and Alternative hypothesis\n",
    "Quantitative Analysis\n",
    "Methodology Code and Explanations\n",
    "(if needed/optional) Supporting Visualizations\n",
    "Findings and Discussion\n",
    "Conclusion regarding the Null Hypothesis\n",
    "Further Instructions:\n",
    "When using random functions, you should make your analysis reproducible by using the np.random.seed() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c077e",
   "metadata": {},
   "source": [
    "### Problem Introduction\n",
    "\n",
    "This assignment is a recreation of Fisher's famous tea-tasting experiment, where we test the ability of individuals to distinguish whether milk or tea was poured first in a cup. In the modern version, we randomly sample 80 STA130 students, 49 of whom correctly identified which was poured first. The question is whether this result could have occurred by random guessing or if there is evidence that STA130 students are better than random at identifying the correct sequence. \n",
    "\n",
    "We will conduct a hypothesis test to assess whether the students' performance is significantly better than random guessing (i.e., a 50/50 chance).\n",
    "\n",
    "### Relationship between this Experiment and the Original Fisher-Bristol Experiment\n",
    "\n",
    "In Fisher's original experiment, the null hypothesis was that Dr. Bristol was guessing (50% chance of being correct for each cup). She correctly identified the order in all 8 cups, and Fisher devised a formal statistical method to test whether this result was due to random chance. In our version, we expand the sample size to 80 STA130 students and assess whether their success rate of 49 out of 80 is significantly better than random guessing.\n",
    "\n",
    "### Statements of the Null Hypothesis and Alternative Hypothesis\n",
    "\n",
    "- **Null Hypothesis (𝐻₀)**: The students are guessing, meaning that the probability of correctly identifying the order of pouring is 50%. Formally, \\( H_0: p = 0.5 \\), where \\( p \\) is the true probability of correctly identifying the order.\n",
    "    - *Informal interpretation*: The students are just as likely to guess correctly as they are to guess incorrectly, and there is no special ability to distinguish the pouring order.\n",
    "  \n",
    "- **Alternative Hypothesis (𝐻₁)**: The students are better than random at identifying whether the tea or milk was poured first. Formally, \\( H_1: p > 0.5 \\).\n",
    "\n",
    "### Quantitative Analysis\n",
    "\n",
    "We will use a binomial test to simulate the sampling distribution under the null hypothesis. Since we expect random guessing, the null hypothesis assumes a binomial distribution with \\( p = 0.5 \\) and \\( n = 80 \\).\n",
    "\n",
    "We will calculate the p-value by comparing the observed number of correct responses (49) to the distribution of results expected if students were guessing randomly.\n",
    "\n",
    "#### Methodology Code and Explanations\n",
    "\n",
    "I'll implement a simulation to estimate the p-value based on 10,000 repetitions, using the binomial distribution under the null hypothesis.\n",
    "\n",
    "Let’s begin by coding this analysis.\n",
    "\n",
    "\n",
    "\n",
    "The p-value from the one-sided binomial test is approximately **0.0283**. This means that if the students were purely guessing, there is a 2.83% chance of observing 49 or more correct answers out of 80.\n",
    "\n",
    "### Interpretation of the p-value and Conclusion\n",
    "\n",
    "Since the p-value is less than the common significance level of 0.05, we have enough evidence to **reject the null hypothesis**. This suggests that the STA130 students are likely better than random at identifying whether the milk or tea was poured first, though the effect is not overwhelmingly strong.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The results of this hypothesis test indicate that the STA130 students' success in identifying the order of pouring is unlikely to be due to chance. However, further experiments with larger sample sizes or more controlled conditions could solidify this finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://chatgpt.com/share/670c310d-c9c8-800b-a967-67e9c7d9d0df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
